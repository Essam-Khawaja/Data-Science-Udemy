{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a808a03",
   "metadata": {},
   "source": [
    "# Building a Simple Linear Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574b2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33dd67",
   "metadata": {},
   "source": [
    "## We are gonna create random, fake linear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b479ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations, 1))\n",
    "zs = np.random.uniform(low=-10, high=10, size=(observations, 1))\n",
    "\n",
    "inputs = np.column_stack((xs, zs))\n",
    "\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93f57a",
   "metadata": {},
   "source": [
    "## Now we create the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40fa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.uniform(low=-1, high=1, size=(observations, 1))\n",
    "\n",
    "targets = 2*xs - 3*zs + 5 + noise       # This is the model we want the algorithm to figure out\n",
    "\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06196370",
   "metadata": {},
   "source": [
    "## Now we initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504c7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_range = 0.1\n",
    "\n",
    "weights = np.random.uniform(low=-init_range, high=init_range, size=(2, 1))\n",
    "\n",
    "biases = np.random.uniform(low=-init_range, high=init_range, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2110ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02    # Chosen from before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d15437",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa01413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38609102625407754\n",
      "0.3772437838560245\n",
      "0.36874553754032374\n",
      "0.3605825205014525\n",
      "0.3527415089913727\n",
      "0.34520980089760905\n",
      "0.33797519516635227\n",
      "0.331025972037263\n",
      "0.32435087405794677\n",
      "0.31793908784734676\n",
      "0.3117802265785191\n",
      "0.3058643131524044\n",
      "0.3001817640353426\n",
      "0.2947233737341461\n",
      "0.28948029988358565\n",
      "0.2844440489221239\n",
      "0.279606462332702\n",
      "0.2749597034262781\n",
      "0.27049624464671945\n",
      "0.2662088553764749\n",
      "0.2620905902232722\n",
      "0.2581347777688753\n",
      "0.2543350097616616\n",
      "0.2506851307355225\n",
      "0.24717922803826264\n",
      "0.24381162225335157\n",
      "0.2405768579995026\n",
      "0.23746969509318488\n",
      "0.23448510005974102\n",
      "0.23161823797937067\n",
      "0.2288644646547587\n",
      "0.22621931908767118\n",
      "0.22367851625232152\n",
      "0.22123794015380924\n",
      "0.21889363716037752\n",
      "0.21664180959869514\n",
      "0.21447880960178395\n",
      "0.21240113319962547\n",
      "0.21040541464287463\n",
      "0.20848842095048803\n",
      "0.20664704667242653\n",
      "0.20487830885895766\n",
      "0.2031793422283993\n",
      "0.201547394525483\n",
      "0.19997982206281623\n",
      "0.19847408543821757\n",
      "0.19702774542099033\n",
      "0.19563845900047164\n",
      "0.19430397559045146\n",
      "0.19302213338331772\n",
      "0.1917908558480166\n",
      "0.1906081483661598\n",
      "0.18947209500082476\n",
      "0.18838085539281724\n",
      "0.1873326617793657\n",
      "0.18632581613041904\n",
      "0.18535868739790845\n",
      "0.18442970887351828\n",
      "0.1835373756506824\n",
      "0.18268024218669876\n",
      "0.1818569199610114\n",
      "0.1810660752258628\n",
      "0.18030642684567952\n",
      "0.1795767442216858\n",
      "0.178875845298384\n",
      "0.1782025946486741\n",
      "0.17755590163450966\n",
      "0.17693471864010868\n",
      "0.17633803937486045\n",
      "0.17576489724317565\n",
      "0.17521436377864275\n",
      "0.17468554713995008\n",
      "0.17417759066614072\n",
      "0.17368967148885706\n",
      "0.17322099919932818\n",
      "0.17277081456794113\n",
      "0.17233838831431986\n",
      "0.17192301992592124\n",
      "0.17152403652323486\n",
      "0.1711407917697451\n",
      "0.17077266482489362\n",
      "0.17041905933834292\n",
      "0.17007940248391415\n",
      "0.16975314403163227\n",
      "0.16943975545637607\n",
      "0.16913872908169036\n",
      "0.1688495772573698\n",
      "0.16857183156948724\n",
      "0.16830504208158203\n",
      "0.16804877660578166\n",
      "0.16780262000267548\n",
      "0.16756617350880604\n",
      "0.16733905409068892\n",
      "0.16712089382431444\n",
      "0.1669113392991263\n",
      "0.16671005104551073\n",
      "0.16651670298486973\n",
      "0.16633098190138826\n",
      "0.16615258693463653\n",
      "0.1659812290921895\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    outputs = np.dot(inputs, weights) + biases  # This is the model\n",
    "    deltas = outputs - targets  # Subtracts corresponding columns in both arrays\n",
    "\n",
    "    loss = np.sum(deltas ** 2) / 2 / observations # Modified L2-Norm formula, just divided by 2 and the observations to get the mean loss\n",
    "\n",
    "    print(loss)\n",
    "\n",
    "    # Updating the weights and biases\n",
    "    deltas_scaled = deltas / observations\n",
    "    weights = weights - learning_rate * np.dot(inputs.T, deltas_scaled) # Gradient descent method, the .T method is for transposing\n",
    "    biases = biases - learning_rate * np.sum(deltas_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5450936",
   "metadata": {},
   "source": [
    "We can see the loss function becoming smaller and smaller, meaning we have a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa86a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0014017 ]\n",
      " [-2.99973248]] [4.86383993]\n"
     ]
    }
   ],
   "source": [
    "print(weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2757d1c",
   "metadata": {},
   "source": [
    "Incredibly close to our original model, which had weights 2 and -3, and a bias of 5. Note that the bias may not be as accurate as we may want. Hence, we just run the loop again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
